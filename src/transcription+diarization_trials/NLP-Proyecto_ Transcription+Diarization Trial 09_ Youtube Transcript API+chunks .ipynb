{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPIAcsqLk2w3Y1WNDeFhoZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgVAs3GB-ymQ","executionInfo":{"status":"ok","timestamp":1761255153177,"user_tz":-120,"elapsed":66921,"user":{"displayName":"Aimar Pagonabarraga Gallastegui","userId":"08004142937794377562"}},"outputId":"48d927e9-3c10-4f0b-c7eb-776d2d78ee1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting youtube-transcript-api\n","  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Collecting yt_dlp\n","  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n","Downloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: yt_dlp, youtube-transcript-api\n","Successfully installed youtube-transcript-api-1.2.3 yt_dlp-2025.10.22\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[1/9] Processing: https://www.youtube.com/watch?v=QM6zUHrSpyo\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] QM6zUHrSpyo: nsig extraction failed: Some formats may be missing\n","         n = mLlG5xUZ44hSXTU0 ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] QM6zUHrSpyo: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] QM6zUHrSpyo: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/¬øCu√°nta PRESI√ìN puede AGUANTAR Israel.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/¬øCu√°nta PRESI√ìN puede AGUANTAR Israel.csv\n","\n","[2/9] Processing: https://www.youtube.com/watch?v=1dAd22MuaUg\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] 1dAd22MuaUg: nsig extraction failed: Some formats may be missing\n","         n = 1exk904elV36xEhd ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] 1dAd22MuaUg: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] 1dAd22MuaUg: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Los _GROYPERS_, ¬øla IDEOLOG√çA detr√°s del ASESINO de CHARLIE KIRK.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Los _GROYPERS_, ¬øla IDEOLOG√çA detr√°s del ASESINO de CHARLIE KIRK.csv\n","\n","[3/9] Processing: https://www.youtube.com/watch?v=exIKS7Y3xV4\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] exIKS7Y3xV4: nsig extraction failed: Some formats may be missing\n","         n = QlPpwszpo-IMsSTw ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] exIKS7Y3xV4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] exIKS7Y3xV4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Nueva POL√çTICA de DEFENSA en EEUU.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Nueva POL√çTICA de DEFENSA en EEUU.csv\n","\n","[4/9] Processing: https://www.youtube.com/watch?v=08xx39f3vW4\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/25f1a420/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] 08xx39f3vW4: nsig extraction failed: Some formats may be missing\n","         n = QNOucWZc1pLWehxB ; player = https://www.youtube.com/s/player/25f1a420/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] 08xx39f3vW4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] 08xx39f3vW4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Trump AMENAZA a ESPA√ëA.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Trump AMENAZA a ESPA√ëA.csv\n","\n","[5/9] Processing: https://www.youtube.com/watch?v=5gxCCXOGYwc\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/25f1a420/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] 5gxCCXOGYwc: nsig extraction failed: Some formats may be missing\n","         n = Jc9ck8CKq9EWmX5Q ; player = https://www.youtube.com/s/player/25f1a420/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] 5gxCCXOGYwc: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] 5gxCCXOGYwc: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Mucho RUIDO y P√âSIMA GESTI√ìN.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Mucho RUIDO y P√âSIMA GESTI√ìN.csv\n","\n","[6/9] Processing: https://www.youtube.com/watch?v=T9M_wZ4Jqm0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] T9M_wZ4Jqm0: nsig extraction failed: Some formats may be missing\n","         n = 6485SNHqoCApRt-w ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] T9M_wZ4Jqm0: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] T9M_wZ4Jqm0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/ENTENDIENDO la OFERTA de RUSIA.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/ENTENDIENDO la OFERTA de RUSIA.csv\n","\n","[7/9] Processing: https://www.youtube.com/watch?v=0-xkCqbuB4g\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] 0-xkCqbuB4g: nsig extraction failed: Some formats may be missing\n","         n = nBqoOF1ZeGPUFGaR ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] 0-xkCqbuB4g: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] 0-xkCqbuB4g: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/INCENDIOS DE VERANO con el INGENIERO T√âCNICO AGR√çCOLA Felipe Mar√≠n.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/INCENDIOS DE VERANO con el INGENIERO T√âCNICO AGR√çCOLA Felipe Mar√≠n.csv\n","\n","[8/9] Processing: https://www.youtube.com/watch?v=_MW9OxwVSq0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] _MW9OxwVSq0: Some tv client https formats have been skipped as they are missing a url. YouTube may have enabled the SABR-only or Server-Side Ad Placement experiment for the current session. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] _MW9OxwVSq0: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] _MW9OxwVSq0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Analizamos el ACUERDO COMERCIAL entre la UE y EEUU.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Analizamos el ACUERDO COMERCIAL entre la UE y EEUU.csv\n","\n","[9/9] Processing: https://www.youtube.com/watch?v=2dQHz2c4RK0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: [youtube] Falling back to generic n function search\n","         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","WARNING: [youtube] 2dQHz2c4RK0: nsig extraction failed: Some formats may be missing\n","         n = LrSzFSFQJ5WiBFna ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n","         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n","WARNING: [youtube] 2dQHz2c4RK0: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n","WARNING: [youtube] 2dQHz2c4RK0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"]},{"output_type":"stream","name":"stdout","text":["üíæ Full transcript saved ‚Üí output_transcripts/Caso MONTORO_ C√ìMO FUNCIONAN las CLOACAS.txt\n","üìÑ Chunk CSV saved ‚Üí transcripts_chunks/csv/Caso MONTORO_ C√ìMO FUNCIONAN las CLOACAS.csv\n","üóúÔ∏è  Zipped full transcripts ‚Üí transcripts_full.zip\n","üóúÔ∏è  Zipped chunk CSVs ‚Üí transcripts_chunks_csv.zip\n","\n","‚úÖ All done\n"]}],"source":["!pip install youtube-transcript-api requests nltk yt_dlp\n","\n","import os\n","import re\n","import csv\n","import time\n","import requests\n","from pathlib import Path\n","from urllib.parse import urlparse, parse_qs\n","from pathlib import Path\n","from zipfile import ZipFile, ZIP_DEFLATED\n","\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n","from youtube_transcript_api.formatters import TextFormatter\n","\n","\n","\n","try:\n","    nltk.data.find(\"tokenizers/punkt\")\n","except LookupError:\n","    nltk.download(\"punkt\")\n","\n","try:\n","    nltk.data.find(\"tokenizers/punkt_tab\")\n","except LookupError:\n","    nltk.download(\"punkt_tab\")\n","\n","try:\n","    from yt_dlp import YoutubeDL\n","    YT_DLP_AVAILABLE = True\n","except Exception:\n","    YT_DLP_AVAILABLE = False\n","\n","\n","ydl_opts = {\n","    \"quiet\": True,\n","    \"no_warnings\": True,\n","    \"skip_download\": True,\n","    \"noplaylist\": True,\n","    \"extract_flat\": True,\n","}\n","\n","# ----------------- Config -----------------\n","URLS = [\n","    \"https://www.youtube.com/watch?v=QM6zUHrSpyo\",\n","    \"https://www.youtube.com/watch?v=1dAd22MuaUg\",\n","    \"https://www.youtube.com/watch?v=exIKS7Y3xV4\",\n","    \"https://www.youtube.com/watch?v=08xx39f3vW4\",\n","    \"https://www.youtube.com/watch?v=5gxCCXOGYwc\",\n","    \"https://www.youtube.com/watch?v=T9M_wZ4Jqm0\",\n","    \"https://www.youtube.com/watch?v=0-xkCqbuB4g\",\n","    \"https://www.youtube.com/watch?v=_MW9OxwVSq0\",\n","    \"https://www.youtube.com/watch?v=2dQHz2c4RK0\"\n","]\n","\n","LANGUAGES = (\"es\", \"es-ES\")\n","OUT_TXT_DIR = Path(\"output_transcripts\")\n","OUT_CSV_DIR = Path(\"transcripts_chunks/csv\")\n","\n","MAX_CHARS_PER_CHUNK = 5000\n","MAX_SENTS_PER_CHUNK = 1\n","SENT_OVERLAP = 0\n","\n","from urllib.parse import urlparse, parse_qs\n","\n","def get_video_id(url: str):\n","    p = urlparse(url)\n","\n","    # Short form: https://youtu.be/VIDEO_ID (may also have extra query like ?t=30s)\n","    if p.netloc in {\"youtu.be\", \"www.youtu.be\"}:\n","        # p.path is like \"/VIDEO_ID\"\n","        vid = p.path.lstrip(\"/\")\n","        # strip any trailing slash or extra junk if present\n","        vid = vid.split(\"/\")[0]\n","        # defensive: remove any accidental query concatenation\n","        vid = vid.split(\"?\")[0]\n","        return vid or None\n","\n","    # Standard form: https://www.youtube.com/watch?v=VIDEO_ID\n","    if p.netloc in {\"www.youtube.com\", \"youtube.com\", \"m.youtube.com\"}:\n","        q = parse_qs(p.query)\n","        v = q.get(\"v\", [None])[0]\n","        if v:\n","            # Sometimes v can be like \"VIDEO_ID&list=...\" if string was malformed\n","            return v.split(\"&\")[0]\n","    return None\n","\n","def sanitize_filename(name: str, max_len: int = 150) -> str:\n","    name = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", name).strip()\n","    name = re.sub(r\"\\s+\", \" \", name)\n","    return name[:max_len].rstrip(\" ._\")\n","\n","\n","def get_video_title(url: str, fallback_id: str) -> str:\n","    if not YT_DLP_AVAILABLE:\n","        return fallback_id\n","    try:\n","        ydl_opts = {\"quiet\": True, \"skip_download\": True}\n","        with YoutubeDL(ydl_opts) as ydl:\n","            info = ydl.extract_info(url, download=False)\n","            title = info.get(\"title\")\n","            if title:\n","                return sanitize_filename(title)\n","    except Exception:\n","        pass\n","    return fallback_id\n","\n","# ----------------- Your classes (unchanged) -----------------\n","class ChunkWriter:\n","    def __init__(self, csv_writer, video_id, max_chars=450, max_sents=5, overlap=1):\n","        self.w = csv_writer\n","        self.video_id = video_id\n","        self.max_chars = max_chars\n","        self.max_sents = max_sents\n","        self.overlap = max(0, overlap)\n","        self.buffer = []\n","        self.chunk_id = 0\n","\n","    def add_segment_sentences(self, sents, seg_start, seg_end):\n","        if not sents:\n","            return\n","        seg_start = float(seg_start or 0.0)\n","        seg_end = float(seg_end or seg_start)\n","        dur = max(0.001, seg_end - seg_start)\n","        per = dur / max(1, len(sents))\n","        for i, s in enumerate(sents):\n","            st = seg_start + i * per\n","            en = seg_start + (i + 1) * per\n","            self.buffer.append({\"text\": s, \"start\": st, \"end\": en})\n","        self._flush_complete()\n","\n","    def _flush_complete(self, force=False):\n","        while self.buffer:\n","            txt = \"\"\n","            count = 0\n","            last = -1\n","            for i, it in enumerate(self.buffer):\n","                cand = ((\" \" + it[\"text\"]) if txt else it[\"text\"])\n","                if count >= self.max_sents:\n","                    break\n","                if len((txt + cand).strip()) > self.max_chars and count > 0:\n","                    break\n","                txt = (txt + cand).strip()\n","                count += 1\n","                last = i\n","\n","            if last == -1:\n","                it = self.buffer[0]\n","                self._write(it[\"start\"], it[\"end\"], it[\"text\"])\n","                del self.buffer[0]\n","                continue\n","\n","            if not force and count <= self.overlap and len(self.buffer) <= self.max_sents:\n","                break\n","\n","            st = self.buffer[0][\"start\"]\n","            en = self.buffer[last][\"end\"]\n","            self._write(st, en, txt)\n","            remove_n = max(1, count - self.overlap) if self.overlap >= 0 else count\n","            self.buffer = self.buffer[remove_n:]\n","\n","        if force and self.buffer:\n","            st = self.buffer[0][\"start\"]\n","            en = self.buffer[-1][\"end\"]\n","            txt = \" \".join([x[\"text\"] for x in self.buffer]).strip()\n","            if txt:\n","                self._write(st, en, txt)\n","            self.buffer.clear()\n","\n","    def _write(self, st, en, text):\n","        self.w.writerow([self.video_id, self.chunk_id, text])\n","        self.chunk_id += 1\n","\n","    def close(self):\n","        self._flush_complete(force=True)\n","\n","# ----------------- NLTK Sentence Assembler -----------------\n","class NLTKSentenceAssembler:\n","    def __init__(self, language=\"spanish\"):\n","        self.lang = language\n","        self.buf_text = \"\"\n","        self.buf_st = None\n","        self.buf_en = None\n","\n","    def add_segment(self, text, seg_start, seg_end):\n","        text = (text or \"\").strip()\n","        if not text:\n","            return []\n","        if self.buf_text:\n","            self.buf_text += \" \" + text\n","            self.buf_st = min(self.buf_st, float(seg_start))\n","            self.buf_en = max(self.buf_en, float(seg_end))\n","        else:\n","            self.buf_text = text\n","            self.buf_st = float(seg_start or 0.0)\n","            self.buf_en = float(seg_end or seg_start)\n","\n","        sents = [s.strip() for s in sent_tokenize(self.buf_text, language=self.lang) if s.strip()]\n","        if not sents:\n","            return []\n","\n","        complete = sents[:-1]\n","        tail = sents[-1] if sents else \"\"\n","\n","        emitted = []\n","        if complete:\n","            st, en = float(self.buf_st), float(self.buf_en)\n","            for s in complete:\n","                emitted.append((s, st, en))\n","            self.buf_text = tail  # keep tail; keep same approx time window\n","\n","        return emitted\n","\n","    def flush(self):\n","        if not self.buf_text.strip():\n","            return []\n","        st = float(self.buf_st or 0.0)\n","        en = float(self.buf_en or st)\n","        out = [(self.buf_text.strip(), st, en)]\n","        self.buf_text = \"\"\n","        self.buf_st = None\n","        self.buf_en = None\n","        return out\n","\n","# ----------------- Processing loop (YouTube API ‚Üí chunking) -----------------\n","def process_url(url: str):\n","    video_id = get_video_id(url)\n","    if not video_id:\n","        print(f\"‚õî Could not extract video ID from URL: {url}\")\n","        return\n","\n","    title = get_video_title(url, video_id)\n","    base_name = sanitize_filename(title)\n","    base_name = base_name.lstrip(\". \").strip() or video_id\n","\n","\n","    OUT_TXT_DIR.mkdir(parents=True, exist_ok=True)\n","    OUT_CSV_DIR.mkdir(parents=True, exist_ok=True)\n","\n","    txt_path = OUT_TXT_DIR / f\"{base_name}.txt\"\n","    csv_path = OUT_CSV_DIR / f\"{base_name}.csv\"\n","\n","    ytt_api = YouTubeTranscriptApi()\n","\n","    video_id = get_video_id(url)\n","    if not video_id:\n","        print(f\"‚õî Could not extract video ID from URL: {url}\")\n","\n","    transcript_list = ytt_api.list(video_id)\n","\n","    try:\n","        transcript = transcript_list.find_manually_created_transcript(LANGUAGES)\n","        print(\"‚úÖ Found manual transcript:\", transcript)\n","    except Exception as e:\n","        transcript = transcript_list.find_transcript(LANGUAGES)\n","\n","\n","    # 2) Fetch segments (with timestamps) + write full text\n","    try:\n","        segments = transcript.fetch()  # list[ { 'text', 'start', 'duration' }, ... ]\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Failed to fetch transcript for {base_name}: {e}\")\n","        return\n","\n","    # Save full transcript (.txt) using TextFormatter (for readability)\n","    try:\n","        formatter = TextFormatter()\n","        formatted_text = formatter.format_transcript(segments)\n","        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n","            f.write(formatted_text)\n","        print(f\"üíæ Full transcript saved ‚Üí {txt_path}\")\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Failed writing TXT for {base_name}: {e}\")\n","\n","    # 3) Chunk by sentences ‚Üí CSV\n","    try:\n","        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as fcsv:\n","            writer = csv.writer(fcsv)\n","            writer.writerow([\"video_id\", \"chunk_id\", \"text\"])\n","\n","            cw = ChunkWriter(\n","                writer, video_id,\n","                max_chars=MAX_CHARS_PER_CHUNK,\n","                max_sents=MAX_SENTS_PER_CHUNK,\n","                overlap=SENT_OVERLAP,\n","            )\n","            assembler = NLTKSentenceAssembler(language=\"spanish\")\n","\n","            for seg in segments:\n","                text = getattr(seg, \"text\", None) or (seg.get(\"text\") if isinstance(seg, dict) else None)\n","                if not text:\n","                    continue\n","\n","                st = 0.0\n","                en = 0.0\n","\n","                for sent_text, sst, sen in assembler.add_segment(text.strip(), st, en):\n","                    cw.add_segment_sentences([sent_text], sst, sen)\n","\n","            for sent_text, sst, sen in assembler.flush():\n","                cw.add_segment_sentences([sent_text], sst, sen)\n","\n","            cw.close()\n","\n","        print(f\"üìÑ Chunk CSV saved ‚Üí {csv_path}\")\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Failed writing CSV for {base_name}: {e}\")\n","\n","\n","def main():\n","    t0 = time.time()\n","    for i, url in enumerate(URLS, 1):\n","        print(f\"\\n[{i}/{len(URLS)}] Processing: {url}\")\n","        process_url(url)\n","        time.sleep(2.0)  # politeness\n","\n","\n","    ZIP_TXT = Path(\"transcripts_full.zip\")            # zip for all .txt\n","    ZIP_CSV = Path(\"transcripts_chunks_csv.zip\")      # zip for all .csv\n","\n","    # Overwrite if they already exist\n","    if ZIP_TXT.exists():\n","        ZIP_TXT.unlink()\n","    if ZIP_CSV.exists():\n","        ZIP_CSV.unlink()\n","\n","    # Zip full transcripts\n","    if OUT_TXT_DIR.exists():\n","        with ZipFile(ZIP_TXT, \"w\", compression=ZIP_DEFLATED) as zf:\n","            for p in OUT_TXT_DIR.glob(\"*.txt\"):\n","                zf.write(p, arcname=p.name)  # store flat names\n","        print(f\"üóúÔ∏è  Zipped full transcripts ‚Üí {ZIP_TXT}\")\n","    else:\n","        print(f\"‚ö†Ô∏è  Transcripts folder not found: {OUT_TXT_DIR}\")\n","\n","    # Zip chunk CSVs\n","    if OUT_CSV_DIR.exists():\n","        with ZipFile(ZIP_CSV, \"w\", compression=ZIP_DEFLATED) as zf:\n","            for p in OUT_CSV_DIR.glob(\"*.csv\"):\n","                # keep a tidy path inside the zip: transcripts_chunks/csv/<file.csv>\n","                arc = Path(\"transcripts_chunks\") / \"csv\" / p.name\n","                zf.write(p, arcname=str(arc))\n","        print(f\"üóúÔ∏è  Zipped chunk CSVs ‚Üí {ZIP_CSV}\")\n","    else:\n","        print(f\"‚ö†Ô∏è  Chunk CSV folder not found: {OUT_CSV_DIR}\")\n","\n","    print(f\"\\n‚úÖ All done\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["LANGUAGES = (\"es\", \"es-ES\")\n","OUT_TXT_DIR = Path(\"output_transcripts\")\n","OUT_CSV_DIR = Path(\"transcripts_chunks/csv\")\n","\n","IP_TXT = Path(\"transcripts_full.zip\")\n","ZIP_CSV = Path(\"transcripts_chunks_csv.zip\")\n","\n","ZIP_TXT = Path(\"transcripts_full.zip\")            # zip for all .txt\n","ZIP_CSV = Path(\"transcripts_chunks_csv.zip\")\n","\n","# Overwrite if they already exist\n","if ZIP_TXT.exists():\n","    ZIP_TXT.unlink()\n","if ZIP_CSV.exists():\n","  ZIP_CSV.unlink()\n","\n","# Zip full transcripts\n","if OUT_TXT_DIR.exists():\n","  with ZipFile(ZIP_TXT, \"w\", compression=ZIP_DEFLATED) as zf:\n","      for p in OUT_TXT_DIR.glob(\"*.txt\"):\n","          zf.write(p, arcname=p.name)  # store flat names\n","  print(f\"üóúÔ∏è  Zipped full transcripts ‚Üí {ZIP_TXT}\")\n","else:\n","  print(f\"‚ö†Ô∏è  Transcripts folder not found: {OUT_TXT_DIR}\")\n","\n","# Zip chunk CSVs\n","if OUT_CSV_DIR.exists():\n","  with ZipFile(ZIP_CSV, \"w\", compression=ZIP_DEFLATED) as zf:\n","      for p in OUT_CSV_DIR.glob(\"*.csv\"):\n","          # keep a tidy path inside the zip: transcripts_chunks/csv/<file.csv>\n","          arc = Path(\"transcripts_chunks\") / \"csv\" / p.name\n","          zf.write(p, arcname=str(arc))\n","  print(f\"üóúÔ∏è  Zipped chunk CSVs ‚Üí {ZIP_CSV}\")\n","else:\n","  print(f\"‚ö†Ô∏è  Chunk CSV folder not found: {OUT_CSV_DIR}\")"],"metadata":{"id":"6-ldDo0Y_SgE","executionInfo":{"status":"ok","timestamp":1761255175234,"user_tz":-120,"elapsed":87,"user":{"displayName":"Aimar Pagonabarraga Gallastegui","userId":"08004142937794377562"}},"outputId":"6d855860-5fab-4bc4-fbee-ee9e5273d81e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üóúÔ∏è  Zipped full transcripts ‚Üí transcripts_full.zip\n","üóúÔ∏è  Zipped chunk CSVs ‚Üí transcripts_chunks_csv.zip\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","\n","# Download the archives you created\n","files.download(\"transcripts_full.zip\")\n","files.download(\"transcripts_chunks_csv.zip\")\n","\n","print(f\"\\n‚úÖ All done\")"],"metadata":{"id":"LbEh0C_A_U3R","executionInfo":{"status":"ok","timestamp":1761255192493,"user_tz":-120,"elapsed":30,"user":{"displayName":"Aimar Pagonabarraga Gallastegui","userId":"08004142937794377562"}},"outputId":"d94aa82a-9d71-4f85-8a92-5700404d1582","colab":{"base_uri":"https://localhost:8080/","height":52}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9c75be32-e684-45ba-9466-39a4fcabc81e\", \"transcripts_full.zip\", 139082)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_3ce4b59e-862e-4642-a5db-1759687c5fcc\", \"transcripts_chunks_csv.zip\", 142612)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ All done\n"]}]}]}