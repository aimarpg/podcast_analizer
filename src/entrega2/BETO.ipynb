{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO6f/HwIfnyLEDWSeD65A1K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9cdb2c1fc7b64d4fad3091e2cac6d6f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abc61a8ffcad459e92caad6407d521e0","IPY_MODEL_7fd63035cf124aa89284cf01b0217a0c","IPY_MODEL_8e8225563da1486d91acdab18efab5fd"],"layout":"IPY_MODEL_59c309f4b064483a92daaf647919c208"}},"abc61a8ffcad459e92caad6407d521e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a164a601556044d4979d2cd889268bfd","placeholder":"​","style":"IPY_MODEL_2116c84414bb4604b2899353c21dba5e","value":"tokenizer_config.json: 100%"}},"7fd63035cf124aa89284cf01b0217a0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03c97045ad9a460d8878bd7040a84f19","max":310,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d0cd0c620ac48b395871b9aaa395f3f","value":310}},"8e8225563da1486d91acdab18efab5fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef245ce94dc148d5b4d06626f841d203","placeholder":"​","style":"IPY_MODEL_edbe688506aa4037ade814084e99d7bf","value":" 310/310 [00:00&lt;00:00, 28.1kB/s]"}},"59c309f4b064483a92daaf647919c208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a164a601556044d4979d2cd889268bfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2116c84414bb4604b2899353c21dba5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03c97045ad9a460d8878bd7040a84f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d0cd0c620ac48b395871b9aaa395f3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef245ce94dc148d5b4d06626f841d203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edbe688506aa4037ade814084e99d7bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"467a861587cb41eabd1456d9e7356d81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7a0b6fb97784aa5a3ef2b7689b891a2","IPY_MODEL_8c69b5987c9b44cdb881d08f04c831f6","IPY_MODEL_054362c3c2c74a19a079abcf60d9e4cb"],"layout":"IPY_MODEL_35aea8a460ce4aea9b93abf6944502c9"}},"b7a0b6fb97784aa5a3ef2b7689b891a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f22348b67364a98a19814318b4f4f4f","placeholder":"​","style":"IPY_MODEL_456a1f9c0d3440cdb9ae913a99eba34b","value":"config.json: 100%"}},"8c69b5987c9b44cdb881d08f04c831f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63d14e75377f401cbf78ada019153894","max":650,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9be25325a9b4ff6bdaa8bc46af9d1df","value":650}},"054362c3c2c74a19a079abcf60d9e4cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_979bb262002046658e7ab6f02f2d1a64","placeholder":"​","style":"IPY_MODEL_732e2e3a9ba641e0a9d82d1ff42af4a9","value":" 650/650 [00:00&lt;00:00, 63.6kB/s]"}},"35aea8a460ce4aea9b93abf6944502c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f22348b67364a98a19814318b4f4f4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456a1f9c0d3440cdb9ae913a99eba34b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63d14e75377f401cbf78ada019153894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9be25325a9b4ff6bdaa8bc46af9d1df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"979bb262002046658e7ab6f02f2d1a64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"732e2e3a9ba641e0a9d82d1ff42af4a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"423d7c222f7547b6a4940b57b7c754a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f9e2a188db74af5920fe898a42a38ef","IPY_MODEL_648aba556238469fbe3f11ad83ef70dc","IPY_MODEL_d757af2cf3cc4b199a9893d48e2ae6b2"],"layout":"IPY_MODEL_1c48546760ce420eaa77ddc0aeeaa0c3"}},"3f9e2a188db74af5920fe898a42a38ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_957e6d72a90a4dfe8011cde252ceb7ea","placeholder":"​","style":"IPY_MODEL_8a465a38281e44e0bfba0f6f3a332844","value":"vocab.txt: "}},"648aba556238469fbe3f11ad83ef70dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_647c0e99781e475ea0a622219b8bbfb7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fcb19dafabc45cd8dc512ab7199bd5e","value":1}},"d757af2cf3cc4b199a9893d48e2ae6b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c294153c73384e45aff37179dc94eeec","placeholder":"​","style":"IPY_MODEL_eacda5b7de524a7aa817dd90f981ce02","value":" 248k/? [00:00&lt;00:00, 13.0MB/s]"}},"1c48546760ce420eaa77ddc0aeeaa0c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"957e6d72a90a4dfe8011cde252ceb7ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a465a38281e44e0bfba0f6f3a332844":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"647c0e99781e475ea0a622219b8bbfb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2fcb19dafabc45cd8dc512ab7199bd5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c294153c73384e45aff37179dc94eeec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eacda5b7de524a7aa817dd90f981ce02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"291183fd8c5041049ad5ae09751a9ec0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c76d72b340c4b72bc99bbc8775f114f","IPY_MODEL_46216c65f3e24fa2adb7471f7f6356ea","IPY_MODEL_b2208549ccd7475fadede5ddc6da12e7"],"layout":"IPY_MODEL_83e18ed2db4a49df9205d0d710af90a0"}},"5c76d72b340c4b72bc99bbc8775f114f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a8c055b7264f73bb6b79488b88b73e","placeholder":"​","style":"IPY_MODEL_18e6f057e18f416fad554528c557ad7f","value":"tokenizer.json: "}},"46216c65f3e24fa2adb7471f7f6356ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62ebd0fb6e204eaabd00d1d57fce9393","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33e84a0c40b241b887cc42e02971785b","value":1}},"b2208549ccd7475fadede5ddc6da12e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19e9f3c367c3461da236de1427df16d5","placeholder":"​","style":"IPY_MODEL_37a17af383824d3a837197ec4d8b9534","value":" 486k/? [00:00&lt;00:00, 30.2MB/s]"}},"83e18ed2db4a49df9205d0d710af90a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17a8c055b7264f73bb6b79488b88b73e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18e6f057e18f416fad554528c557ad7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62ebd0fb6e204eaabd00d1d57fce9393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"33e84a0c40b241b887cc42e02971785b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19e9f3c367c3461da236de1427df16d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a17af383824d3a837197ec4d8b9534":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67b1ca4b7b194de3acc7c2c825744453":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bf7b5b0456c4f8ab522b6c7651aa2e6","IPY_MODEL_001bb59f062947d3b8cfc36b567d2f1a","IPY_MODEL_ea23ee4fda9c4baa9d28b8d1f4aa44c2"],"layout":"IPY_MODEL_58bdfe6efc9c4dca869b9b2aa11d7b57"}},"3bf7b5b0456c4f8ab522b6c7651aa2e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_424242c78e06495ea5baf20aa18d870c","placeholder":"​","style":"IPY_MODEL_6602f97d5e884545a687c965eef22b88","value":"special_tokens_map.json: 100%"}},"001bb59f062947d3b8cfc36b567d2f1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c132c9c0dc9b47c48ee5562d968c717f","max":134,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c61fa059c1a48aab07cbdcfcab41182","value":134}},"ea23ee4fda9c4baa9d28b8d1f4aa44c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97e6e3f3265a4fd79b399722d68b68c9","placeholder":"​","style":"IPY_MODEL_236bb00277a841dea4715e7e3b382380","value":" 134/134 [00:00&lt;00:00, 15.2kB/s]"}},"58bdfe6efc9c4dca869b9b2aa11d7b57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424242c78e06495ea5baf20aa18d870c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6602f97d5e884545a687c965eef22b88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c132c9c0dc9b47c48ee5562d968c717f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c61fa059c1a48aab07cbdcfcab41182":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97e6e3f3265a4fd79b399722d68b68c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"236bb00277a841dea4715e7e3b382380":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48ce9335acf34fd48d2aefb6ccdf4088":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdb7ec2f3bf848cf9799b4dfd1ade363","IPY_MODEL_db46faeac22d418db43a1ef35232bb9b","IPY_MODEL_2cb547622a164623a7255999fdae13a8"],"layout":"IPY_MODEL_3589ab3638e54e8586223e75e423859e"}},"cdb7ec2f3bf848cf9799b4dfd1ade363":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ae7a447017d4efeb5f67dc1be0e9c02","placeholder":"​","style":"IPY_MODEL_f760fc10fb1f4f988e318eca5182301a","value":"pytorch_model.bin: 100%"}},"db46faeac22d418db43a1ef35232bb9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf2ba11def2424f82d90ce6943c87a2","max":439621341,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26ff886511f54f8f8517bf71650923af","value":439621341}},"2cb547622a164623a7255999fdae13a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b98cb29192e42f5b95c775dba3f2a38","placeholder":"​","style":"IPY_MODEL_2efc4fcd411e44cdaf4f210b47485a1e","value":" 440M/440M [00:08&lt;00:00, 60.1MB/s]"}},"3589ab3638e54e8586223e75e423859e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ae7a447017d4efeb5f67dc1be0e9c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f760fc10fb1f4f988e318eca5182301a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baf2ba11def2424f82d90ce6943c87a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ff886511f54f8f8517bf71650923af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b98cb29192e42f5b95c775dba3f2a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2efc4fcd411e44cdaf4f210b47485a1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"425ec0c07d5346859637039e14998c72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fedfb054d7dd4f989836a5ff7cf139ed","IPY_MODEL_7ecd664295d64ac5a3a32be42ba0f07e","IPY_MODEL_abf120f295d3443a9c023cfa630515f8"],"layout":"IPY_MODEL_012f8e708d724d538a10cc75a1a011f3"}},"fedfb054d7dd4f989836a5ff7cf139ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f7f834604947c893242d5ec5a80ccc","placeholder":"​","style":"IPY_MODEL_0a170fc07e394c939f9923140a190d6c","value":"model.safetensors: 100%"}},"7ecd664295d64ac5a3a32be42ba0f07e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_603f9c7adf604df0b2f2a19dc007a053","max":439561688,"min":0,"orientation":"horizontal","style":"IPY_MODEL_609d1d70271a4179afc708c3322ef026","value":439561688}},"abf120f295d3443a9c023cfa630515f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_481b26ff00a542c4b09eca83bc104dc0","placeholder":"​","style":"IPY_MODEL_557a5028d29849f699b48eec342e33ae","value":" 440M/440M [00:05&lt;00:00, 106MB/s]"}},"012f8e708d724d538a10cc75a1a011f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f7f834604947c893242d5ec5a80ccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a170fc07e394c939f9923140a190d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"603f9c7adf604df0b2f2a19dc007a053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"609d1d70271a4179afc708c3322ef026":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"481b26ff00a542c4b09eca83bc104dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"557a5028d29849f699b48eec342e33ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","\n","BASE_DIR = \"/content/drive/Shareddrives/NLP/transcriptions\"\n","TEXT_DIR = os.path.join(BASE_DIR, \"all_transcriptions\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnFi79R8qo-L","executionInfo":{"status":"ok","timestamp":1761684963158,"user_tz":-60,"elapsed":33881,"user":{"displayName":"Leire Larrauri Olarte","userId":"15613160182125551834"}},"outputId":"8e253004-2b89-47f8-d97f-57345659a8a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Case-folding, lemmatization, stopword removal and lemmatization"],"metadata":{"id":"BBMeRokXv9he"}},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download es_core_news_sm\n","\n","import os\n","import glob\n","import csv\n","import re\n","import unicodedata\n","import spacy\n","\n","\n","OUTPUT_DIR  = r\"/content/output/preprocessing_steps\"\n","SPACY_MODEL = \"es_core_news_sm\"\n","REMOVE_STOPWORDS = True\n","\n","TOKEN_PATTERN = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]{2,}$\")\n","\n","def normalize_text(text: str) -> str:\n","    \"\"\"Unicode normalize + lowercase (case folding).\"\"\"\n","    return unicodedata.normalize(\"NFKC\", text).lower()\n","\n","def ensure_dir(path: str):\n","    os.makedirs(path, exist_ok=True)\n","\n","def main():\n","    ensure_dir(OUTPUT_DIR)\n","    print(f\"Cargando modelo spaCy: {SPACY_MODEL}\")\n","    nlp = spacy.load(SPACY_MODEL, disable=[\"ner\"])\n","\n","    files = sorted(glob.glob(os.path.join(TEXT_DIR, \"*.txt\")))\n","    if not files:\n","        raise FileNotFoundError(f\"No se encuentran .txt en: {TEXT_DIR}\")\n","\n","    index_rows = []\n","    for path in files:\n","        base = os.path.splitext(os.path.basename(path))[0]\n","        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","            text = f.read()\n","\n","        doc = nlp(normalize_text(text))\n","\n","        raw_tokens, lemmas = [], []\n","        for tok in doc:\n","            if tok.is_space:\n","                continue\n","            if not TOKEN_PATTERN.match(tok.text):\n","                continue\n","            if REMOVE_STOPWORDS and tok.is_stop:\n","                continue\n","            raw_tokens.append(tok.text)\n","            lemmas.append(tok.lemma_ if tok.lemma_ else tok.text)\n","\n","        # --- Save cleaned outputs ---\n","        with open(os.path.join(OUTPUT_DIR, f\"{base}__clean_raw.txt\"), \"w\", encoding=\"utf-8\") as f:\n","            f.write(\" \".join(raw_tokens))\n","        with open(os.path.join(OUTPUT_DIR, f\"{base}__clean_lemma.txt\"), \"w\", encoding=\"utf-8\") as f:\n","            f.write(\" \".join(lemmas))\n","\n","        # Per-document CSV (raw vs lemma)\n","        per_doc_csv = os.path.join(OUTPUT_DIR, f\"{base}__tokens.csv\")\n","        max_len = max(len(raw_tokens), len(lemmas))\n","        with open(per_doc_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","            w = csv.writer(f)\n","            w.writerow([\"raw\", \"lemma\"])\n","            for i in range(max_len):\n","                w.writerow([\n","                    raw_tokens[i] if i < len(raw_tokens) else \"\",\n","                    lemmas[i] if i < len(lemmas) else \"\"\n","                ])\n","\n","        index_rows.append([os.path.basename(path), len(raw_tokens), len(set(raw_tokens))])\n","        print(f\"Procesado: {os.path.basename(path)}  (tokens: {len(raw_tokens)}, únicos: {len(set(raw_tokens))})\")\n","\n","    # Corpus index\n","    with open(os.path.join(OUTPUT_DIR, \"_corpus_index.csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        w = csv.writer(f)\n","        w.writerow([\"file\", \"token_count\", \"unique_token_count\"])\n","        w.writerows(index_rows)\n","\n","    print(\"\\nListo. Salidas en:\", OUTPUT_DIR)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8TEjZVuv77K","executionInfo":{"status":"ok","timestamp":1761685094868,"user_tz":-60,"elapsed":131722,"user":{"displayName":"Leire Larrauri Olarte","userId":"15613160182125551834"}},"outputId":"348a3671-42e3-4cc4-df8c-c5cb1a19b568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting es-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m149.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Cargando modelo spaCy: es_core_news_sm\n","Procesado: 11 Hábitos Diarios para tener una Salud del 1% (Fuerza Explosiva).txt  (tokens: 6047, únicos: 2132)\n","Procesado: 15 Hábitos para Vivir con Abundancia y Tener Éxito (Sergio Fernández).txt  (tokens: 5447, únicos: 2079)\n","Procesado: 299 DÍAS SECUESTRADO, ¿cómo es ser REPORTERO DE GUERRA_ - Tenía la Duda 2x01.txt  (tokens: 1674, únicos: 981)\n","Procesado: ABOGADOS TUMBAN los BULOS sobre EXTRANJERÍA.txt  (tokens: 5175, únicos: 2660)\n","Procesado: ARANCELES_ TRUMP REVIENTA SU PROPIA BOLSA.txt  (tokens: 2323, únicos: 1178)\n","Procesado: Analizamos el ACUERDO COMERCIAL entre la UE y EEUU.txt  (tokens: 2755, únicos: 1282)\n","Procesado: Armados pero bien mandados.txt  (tokens: 2843, únicos: 1518)\n","Procesado: Así es TRABAJAR de TANATOPRACTORA_ ¿Maquilladora de muertos.txt  (tokens: 1033, únicos: 633)\n","Procesado: Así es VIVIR CON AUTISMO_ Lo que no sabíamos _ Tenía la Duda 3x08.txt  (tokens: 990, únicos: 610)\n","Procesado: Así es VIVIR de ATRACAR BANCOS_ Lo que las películas no enseñan.txt  (tokens: 1103, únicos: 680)\n","Procesado: Así es la vida de una MONJA DE CLAUSURA _ Tenía La Duda 1x02.txt  (tokens: 1251, únicos: 700)\n","Procesado: Así es ser MUJER CULTURISTA_ ¿cuánto ganan y cómo entrenan_ ¿usan sustancias.txt  (tokens: 965, únicos: 578)\n","Procesado: Así es vivir con SÍNDROME DE DOWN_ explicado en primera persona.txt  (tokens: 828, únicos: 506)\n","Procesado: Así es vivir con TOC_ explicado en primera persona _ Tenía la Duda 5x07.txt  (tokens: 825, únicos: 462)\n","Procesado: Así se resolvió el primer crimen de la historia _ Tenía La Duda 1x01.txt  (tokens: 1089, únicos: 729)\n","Procesado: ÁFRICA y las MATERIAS PRIMAS.txt  (tokens: 1072, únicos: 596)\n","Procesado: CAYENDO por su propio PESO.txt  (tokens: 1827, únicos: 981)\n","Procesado: CÁRCEL por PROTESTAR (con Francho AIJÓN).txt  (tokens: 3165, únicos: 1507)\n","Procesado: COMUNICACIÓN POLÍTICA y HEGEMONÍA.txt  (tokens: 3184, únicos: 1650)\n","Procesado: Caso MONTORO_ CÓMO FUNCIONAN las CLOACAS.txt  (tokens: 2299, únicos: 1203)\n","Procesado: Cómo Escapar del Sistema y Vivir la Vida que sueñas (Llados Fitness).txt  (tokens: 6914, únicos: 2275)\n","Procesado: Cómo Ganar +10.000€ al Mes con 17 Años (DollarDorado).txt  (tokens: 4316, únicos: 1634)\n","Procesado: Cómo Hizo su Empresa de 1.000.000€ con Sólo 22 Años (Gala Freixa).txt  (tokens: 2395, únicos: 1165)\n","Procesado: Cómo Influenciar al Mundo con tu Comunicación (Fer Miralles).txt  (tokens: 7053, únicos: 2960)\n","Procesado: Cómo Ser Libre con la Inversión Inmobiliaria con Poco Dinero (Carlos Galán).txt  (tokens: 4255, únicos: 1621)\n","Procesado: Cómo Ser un Líder y un Emprendedor de Éxito (Powerexplosive).txt  (tokens: 6787, únicos: 2394)\n","Procesado: Cómo Superar una Ruptura de Amor y Ser tu mejor Versión.txt  (tokens: 5136, únicos: 2055)\n","Procesado: Cómo Tener una Mentalidad de Éxito para Ser el Mejor (Joan Pradells).txt  (tokens: 4980, únicos: 1860)\n","Procesado: Cómo Vender casi Cualquier Cosa Online (Experto Facebook Ads).txt  (tokens: 5017, únicos: 1991)\n","Procesado: Cómo la DERECHA ALTERNATIVA se convirtió en MAINSTREAM.txt  (tokens: 1966, únicos: 1061)\n","Procesado: Cómo ser una persona del top 1% mundial (Adrià Solà Pastor).txt  (tokens: 6614, únicos: 2751)\n","Procesado: Cómo tener el Mejor Sexo de tu Vida y sus Beneficios (sexóloga).txt  (tokens: 4412, únicos: 1721)\n","Procesado: Crimen y castigo – Debate Directo 19-3-2018.txt  (tokens: 4669, únicos: 2311)\n","Procesado: DOMINATRIX PROFESIONAL responde VUESTRAS PREGUNTAS _ Tenía la Duda 1x09.txt  (tokens: 841, únicos: 556)\n","Procesado: De 0€ a 16.530€ con el Podcast en 5 Meses (Especial 100k).txt  (tokens: 5445, únicos: 2135)\n","Procesado: De Cocinar en la Calle a Conquistar Nueva York (Chef Jose Luis).txt  (tokens: 3961, únicos: 1787)\n","Procesado: De Vivir en un Almacén a 3.000.000€ en un Mes (Preico Juridicos).txt  (tokens: 6137, únicos: 2567)\n","Procesado: De la OBRA a 1.000.000€ con Amazon en 3 Años (Ruben AMZ).txt  (tokens: 4754, únicos: 1812)\n","Procesado: ENTENDIENDO la OFERTA de RUSIA.txt  (tokens: 1332, únicos: 758)\n","Procesado: ENVÍA BUQUES de GUERRA y DESTRUCTORES a VENEZUELA.txt  (tokens: 1256, únicos: 721)\n","Procesado: ESPECIAL_ SIRIA AFECTARÁ a TODA la GEOPOLÍTICA.txt  (tokens: 4864, únicos: 2178)\n","Procesado: EUROPA FLIRTEA CON LA ULTRADERECHA.txt  (tokens: 1821, únicos: 970)\n","Procesado: EUROPA_ del verde ECOLOGISTA al verde MILITAR.txt  (tokens: 2927, únicos: 1551)\n","Procesado: El BRAZO ARMADO de TRUMP.txt  (tokens: 2674, únicos: 1360)\n","Procesado: El PLAN de EUROPA para la DERECHA.txt  (tokens: 1866, únicos: 944)\n","Procesado: El PLAN de ILLA para CATALUÑA.txt  (tokens: 1051, únicos: 606)\n","Procesado: El SECRETO mejor guardado del FRIGOPIÉ _ Tenía la duda 1x04.txt  (tokens: 746, únicos: 512)\n","Procesado: El SÍNTOMA de un ENORME PROBLEMA POLÍTICO.txt  (tokens: 1803, únicos: 1002)\n","Procesado: El _TODOS son IGUALES_ y la _ANTIPOLÍTICA.txt  (tokens: 2420, únicos: 1344)\n","Procesado: España, SAHARA y Marruecos_ las CLAVES del CONFLICTO con TALEB ALISALEM.txt  (tokens: 3446, únicos: 1502)\n","Procesado: FEMINISMO DE CLASE MEDIA.txt  (tokens: 3189, únicos: 1464)\n","Procesado: Gana 65.000€ al Mes con 17 Años (Anas Escríbelo.ai).txt  (tokens: 6624, únicos: 2384)\n","Procesado: HUELGA en la EDUCACIÓN PÚBLICA.txt  (tokens: 1711, únicos: 940)\n","Procesado: Ha Creado una Empresa de 40 Millones con 25 años (Internxt).txt  (tokens: 5507, únicos: 2073)\n","Procesado: Habla la ABOGADA de las SEIS de la SUIZA.txt  (tokens: 1450, únicos: 768)\n","Procesado: INCENDIOS DE VERANO con el INGENIERO TÉCNICO AGRÍCOLA Felipe Marín.txt  (tokens: 5369, únicos: 2242)\n","Procesado: INTELIGENCIA ARTIFICIAL_ prepararse para su LLEGADA.txt  (tokens: 1971, únicos: 1038)\n","Procesado: Ingeniero de REDES ELÉCTRICAS HABLA sobre el APAGÓN.txt  (tokens: 3267, únicos: 1480)\n","Procesado: La HIPNOSIS_ finalmente BIEN EXPLICADA por un EXPERTO _ Tenía la Duda.txt  (tokens: 1153, únicos: 667)\n","Procesado: La INQUIETANTE HISTORIA de COCA-COLA _ Tenía la duda 1x05.txt  (tokens: 1202, únicos: 712)\n","Procesado: La REALIDAD de TRABAJAR en un CIRCO_ Los Payasos de la Tele _ Tenía la Duda 4x07.txt  (tokens: 892, únicos: 566)\n","Procesado: La RECONCILIACIÓN que NUNCA FUE.txt  (tokens: 3031, únicos: 1716)\n","Procesado: La situación en EEUU es MUY CERCANA a la RUPTURA.txt  (tokens: 3124, únicos: 1796)\n","Procesado: Las CLAVES del DISCURSO de ALVISE.txt  (tokens: 1846, únicos: 1010)\n","Procesado: Las MEDIDAS que SÍ BAJARÍAN el PRECIO de la VIVIENDA.txt  (tokens: 1655, únicos: 879)\n","Procesado: Los 6 de ZARAGOZA_ ENTREVISTA con FRANCHO AIJÓN, PADRE de uno de los ENCARCELADOS.txt  (tokens: 2101, únicos: 1170)\n","Procesado: Los DINOSAURIOS TODAVÍA EXISTEN_ Paleontólogo explica dónde.txt  (tokens: 992, únicos: 663)\n","Procesado: Los SECRETOS mejor guardados del ANTIGUO EGIPTO _ Tenía la duda 1x08 @Historiaen5minutos.txt  (tokens: 936, únicos: 636)\n","Procesado: Los _GROYPERS_, ¿la IDEOLOGÍA detrás del ASESINO de CHARLIE KIRK.txt  (tokens: 2170, únicos: 1168)\n","Procesado: Los extraterrestres EXISTEN, ¿por qué no los hemos visto todavía_ _ Tenía la Duda 1x10.txt  (tokens: 1719, únicos: 885)\n","Procesado: Lucha IDEOLÓGICA en el VATICANO.txt  (tokens: 1810, únicos: 1012)\n","Procesado: Mayor SMI y reducción de jornada_ ¿se queda corto.txt  (tokens: 1315, únicos: 700)\n","Procesado: Mucho RUIDO y PÉSIMA GESTIÓN.txt  (tokens: 1577, únicos: 842)\n","Procesado: Nueva POLÍTICA de DEFENSA en EEUU.txt  (tokens: 1580, únicos: 848)\n","Procesado: PERDIENDO con el DISCURSO de la DERECHA.txt  (tokens: 1574, únicos: 951)\n","Procesado: POR QUÉ NOS ENAMORAMOS de una persona y NO de otra.txt  (tokens: 681, únicos: 400)\n","Procesado: Por qué SÍ HAY QUE HABLAR DE POLÍTICA en el APAGÓN.txt  (tokens: 2418, únicos: 1380)\n","Procesado: Por qué el 97% de la Población No es Feliz realmente (Psiquiatra Dr. de la Gándara).txt  (tokens: 6791, únicos: 2534)\n","Procesado: Por qué el 99% de las Emprendedores Fracasan y Cómo Empezar.txt  (tokens: 3398, únicos: 1483)\n","Procesado: Por qué los Chinos Emprenden sólo Bazar o Wok en España.txt  (tokens: 2989, únicos: 1339)\n","Procesado: Pregunté a un Millonario el Método para Ganar 1.000.000€ (Hermo Benito).txt  (tokens: 4962, únicos: 1944)\n","Procesado: QUÉ HAY EN JUEGO en la FUSIÓN del BBVA y el SABADELL.txt  (tokens: 1901, únicos: 994)\n","Procesado: RETIRADA en el PRIMER ASALTO.txt  (tokens: 1933, únicos: 1083)\n","Procesado: Republicanismo contra el AUTORITARISMO que VIENE.txt  (tokens: 2253, únicos: 1065)\n","Procesado: Se ACABÓ el EXPERIMENTO (salió MAL).txt  (tokens: 2986, únicos: 1459)\n","Procesado: Situación INSOSTENIBLE en GAZA.txt  (tokens: 1513, únicos: 907)\n","Procesado: TRUMP y la ILUSTRACIÓN OSCURA.txt  (tokens: 1118, únicos: 609)\n","Procesado: Torre Pacheco es una ADVERTENCIA.txt  (tokens: 3005, únicos: 1404)\n","Procesado: Trump AMENAZA a ESPAÑA.txt  (tokens: 1823, únicos: 969)\n","Procesado: Un MANUAL para MANIPULAR las DEMOCRACIAS.txt  (tokens: 770, únicos: 497)\n","Procesado: y la SEGUNDA OLEADA de NUEVA IZQUIERDA.txt  (tokens: 3648, únicos: 1674)\n","Procesado: ¿Cuánta PRESIÓN puede AGUANTAR Israel.txt  (tokens: 1884, únicos: 1030)\n","Procesado: ¿DIMITE HOY Pedro Sánchez.txt  (tokens: 5022, únicos: 2161)\n","Procesado: ¿GIRO a la IZQUIERDA de Pedro SÁNCHEZ.txt  (tokens: 1860, únicos: 976)\n","Procesado: ¿Hasta dónde puede llegar el Gobierno.txt  (tokens: 2015, únicos: 1009)\n","Procesado: ¿MAGA contra SILICON VALLEY.txt  (tokens: 1893, únicos: 1064)\n","Procesado: ¿Por qué dejaron de CAMINAR los DELFINES_ _ Tenía la Duda 1x03.txt  (tokens: 1260, únicos: 829)\n","Procesado: ¿Por qué el 666 es el NÚMERO DE SATANÁS_ La verdadera historia _ Tenía la Duda 2x06.txt  (tokens: 1184, únicos: 774)\n","Procesado: ¿Puede REMONTAR la IZQUIERDA.txt  (tokens: 1693, únicos: 915)\n","Procesado: ¿Puede provocar TRUMP una GUERRA MUNDIAL.txt  (tokens: 1764, únicos: 929)\n","Procesado: ¿QUÉ SENTIMOS AL MORIR_ ¿Y de qué nos solemos arrepentir.txt  (tokens: 1037, únicos: 610)\n","Procesado: ¿Qué SECRETOS ocultaban los PRIMEROS HUMANOS_ Así eran LOS NEANDERTALES.txt  (tokens: 970, únicos: 594)\n","Procesado: ¿Qué busca el Gobierno de TRUMP.txt  (tokens: 1852, únicos: 1031)\n","Procesado: ¿Qué puede hacer Europa ante TRUMP y VANCE.txt  (tokens: 1882, únicos: 1104)\n","\n","Listo. Salidas en: /content/output/preprocessing_steps\n"]}]},{"cell_type":"markdown","source":["Pre-trained model"],"metadata":{"id":"sW_8h_cG1Ymf"}},{"cell_type":"code","source":["import os\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load BETO model and tokenizer\n","model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)\n","model.to(device)\n","model.eval()  # Set to evaluation mode\n","\n","print(\"BETO model loaded successfully!\")\n","\n","def get_embeddings(text, method=\"mean\"):\n","    \"\"\"\n","    Get contextual embeddings for a text using BETO\n","\n","    Args:\n","        text (str): Input text\n","        method (str): How to aggregate token embeddings\n","                     \"mean\" - mean of all token embeddings\n","                     \"cls\" - use [CLS] token embedding\n","                     \"pooler\" - use pooler output\n","\n","    Returns:\n","        numpy array: Embedding vector\n","    \"\"\"\n","    # Tokenize the text\n","    inputs = tokenizer(\n","        text,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=True,\n","        max_length=512,  # BERT's maximum length\n","        return_attention_mask=True\n","    )\n","\n","    # Move to device\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","    # Get embeddings without calculating gradients\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # Choose embedding aggregation method\n","    if method == \"cls\":\n","        # Use [CLS] token embedding\n","        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","    elif method == \"mean\":\n","        # Mean of all token embeddings (excluding padding tokens)\n","        attention_mask = inputs['attention_mask']\n","        token_embeddings = outputs.last_hidden_state\n","\n","        # Create mask for non-padding tokens\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","\n","        # Sum embeddings and divide by number of non-padding tokens\n","        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","        embedding = (sum_embeddings / sum_mask).cpu().numpy()\n","    elif method == \"pooler\":\n","        # Use pooler output\n","        embedding = outputs.pooler_output.cpu().numpy()\n","    else:\n","        raise ValueError(\"Method must be 'mean', 'cls', or 'pooler'\")\n","\n","    return embedding.squeeze()\n","\n","def process_transcript_files(text_dir, output_file=\"beto_embeddings.csv\"):\n","    \"\"\"\n","    Process all transcript files and generate BETO embeddings\n","\n","    Args:\n","        text_dir (str): Directory containing transcript files\n","        output_file (str): Name of output CSV file\n","    \"\"\"\n","    # Get all text files\n","    text_files = [f for f in os.listdir(text_dir) if f.endswith('.txt')]\n","    print(f\"Found {len(text_files)} transcript files\")\n","\n","    embeddings_data = []\n","\n","    for filename in tqdm(text_files, desc=\"Processing files\"):\n","        file_path = os.path.join(text_dir, filename)\n","\n","        try:\n","            # Read the transcript\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                transcript = f.read().strip()\n","\n","            if not transcript:\n","                print(f\"Warning: Empty file {filename}\")\n","                continue\n","\n","            # Get embeddings using different methods\n","            mean_embedding = get_embeddings(transcript, method=\"mean\")\n","            cls_embedding = get_embeddings(transcript, method=\"cls\")\n","\n","            # Store results\n","            embeddings_data.append({\n","                'filename': filename,\n","                'text_length': len(transcript),\n","                'mean_embedding': mean_embedding.tolist(),\n","                'cls_embedding': cls_embedding.tolist(),\n","                'embedding_dim': len(mean_embedding)\n","            })\n","\n","        except Exception as e:\n","            print(f\"Error processing {filename}: {str(e)}\")\n","            continue\n","\n","    # Create DataFrame and save\n","    df = pd.DataFrame(embeddings_data)\n","\n","    # Save to CSV\n","    output_path = os.path.join(BASE_DIR, output_file)\n","    df.to_csv(output_path, index=False)\n","    print(f\"Embeddings saved to {output_path}\")\n","\n","    return df\n","\n","# Function to load and visualize embeddings\n","def load_and_analyze_embeddings(csv_path):\n","    \"\"\"\n","    Load saved embeddings and provide basic analysis\n","    \"\"\"\n","    df = pd.read_csv(csv_path)\n","\n","    print(\"Embeddings DataFrame Info:\")\n","    print(f\"Shape: {df.shape}\")\n","    print(f\"Columns: {df.columns.tolist()}\")\n","    print(f\"Embedding dimension: {df['embedding_dim'].iloc[0]}\")\n","\n","    # Convert string representations back to numpy arrays\n","    df['mean_embedding_array'] = df['mean_embedding'].apply(\n","        lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x)\n","    )\n","    df['cls_embedding_array'] = df['cls_embedding'].apply(\n","        lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x)\n","    )\n","\n","    return df\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Process all transcript files\n","    print(\"Starting BETO embedding generation...\")\n","    embeddings_df = process_transcript_files(TEXT_DIR)\n","\n","    # Display basic info\n","    print(\"\\nEmbedding generation completed!\")\n","    print(f\"Processed {len(embeddings_df)} files\")\n","    print(f\"Embedding dimension: {embeddings_df['embedding_dim'].iloc[0]}\")\n","\n","    # Example: Access embeddings for the first file\n","    if len(embeddings_df) > 0:\n","        first_embedding = np.array(embeddings_df['mean_embedding'].iloc[0])\n","        print(f\"First embedding shape: {first_embedding.shape}\")\n","        print(f\"First embedding sample (first 10 dims): {first_embedding[:10]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643,"referenced_widgets":["9cdb2c1fc7b64d4fad3091e2cac6d6f0","abc61a8ffcad459e92caad6407d521e0","7fd63035cf124aa89284cf01b0217a0c","8e8225563da1486d91acdab18efab5fd","59c309f4b064483a92daaf647919c208","a164a601556044d4979d2cd889268bfd","2116c84414bb4604b2899353c21dba5e","03c97045ad9a460d8878bd7040a84f19","5d0cd0c620ac48b395871b9aaa395f3f","ef245ce94dc148d5b4d06626f841d203","edbe688506aa4037ade814084e99d7bf","467a861587cb41eabd1456d9e7356d81","b7a0b6fb97784aa5a3ef2b7689b891a2","8c69b5987c9b44cdb881d08f04c831f6","054362c3c2c74a19a079abcf60d9e4cb","35aea8a460ce4aea9b93abf6944502c9","4f22348b67364a98a19814318b4f4f4f","456a1f9c0d3440cdb9ae913a99eba34b","63d14e75377f401cbf78ada019153894","a9be25325a9b4ff6bdaa8bc46af9d1df","979bb262002046658e7ab6f02f2d1a64","732e2e3a9ba641e0a9d82d1ff42af4a9","423d7c222f7547b6a4940b57b7c754a5","3f9e2a188db74af5920fe898a42a38ef","648aba556238469fbe3f11ad83ef70dc","d757af2cf3cc4b199a9893d48e2ae6b2","1c48546760ce420eaa77ddc0aeeaa0c3","957e6d72a90a4dfe8011cde252ceb7ea","8a465a38281e44e0bfba0f6f3a332844","647c0e99781e475ea0a622219b8bbfb7","2fcb19dafabc45cd8dc512ab7199bd5e","c294153c73384e45aff37179dc94eeec","eacda5b7de524a7aa817dd90f981ce02","291183fd8c5041049ad5ae09751a9ec0","5c76d72b340c4b72bc99bbc8775f114f","46216c65f3e24fa2adb7471f7f6356ea","b2208549ccd7475fadede5ddc6da12e7","83e18ed2db4a49df9205d0d710af90a0","17a8c055b7264f73bb6b79488b88b73e","18e6f057e18f416fad554528c557ad7f","62ebd0fb6e204eaabd00d1d57fce9393","33e84a0c40b241b887cc42e02971785b","19e9f3c367c3461da236de1427df16d5","37a17af383824d3a837197ec4d8b9534","67b1ca4b7b194de3acc7c2c825744453","3bf7b5b0456c4f8ab522b6c7651aa2e6","001bb59f062947d3b8cfc36b567d2f1a","ea23ee4fda9c4baa9d28b8d1f4aa44c2","58bdfe6efc9c4dca869b9b2aa11d7b57","424242c78e06495ea5baf20aa18d870c","6602f97d5e884545a687c965eef22b88","c132c9c0dc9b47c48ee5562d968c717f","4c61fa059c1a48aab07cbdcfcab41182","97e6e3f3265a4fd79b399722d68b68c9","236bb00277a841dea4715e7e3b382380","48ce9335acf34fd48d2aefb6ccdf4088","cdb7ec2f3bf848cf9799b4dfd1ade363","db46faeac22d418db43a1ef35232bb9b","2cb547622a164623a7255999fdae13a8","3589ab3638e54e8586223e75e423859e","1ae7a447017d4efeb5f67dc1be0e9c02","f760fc10fb1f4f988e318eca5182301a","baf2ba11def2424f82d90ce6943c87a2","26ff886511f54f8f8517bf71650923af","4b98cb29192e42f5b95c775dba3f2a38","2efc4fcd411e44cdaf4f210b47485a1e","425ec0c07d5346859637039e14998c72","fedfb054d7dd4f989836a5ff7cf139ed","7ecd664295d64ac5a3a32be42ba0f07e","abf120f295d3443a9c023cfa630515f8","012f8e708d724d538a10cc75a1a011f3","42f7f834604947c893242d5ec5a80ccc","0a170fc07e394c939f9923140a190d6c","603f9c7adf604df0b2f2a19dc007a053","609d1d70271a4179afc708c3322ef026","481b26ff00a542c4b09eca83bc104dc0","557a5028d29849f699b48eec342e33ae"]},"id":"ycl5wqeYxTSw","executionInfo":{"status":"ok","timestamp":1761685141276,"user_tz":-60,"elapsed":46041,"user":{"displayName":"Leire Larrauri Olarte","userId":"15613160182125551834"}},"outputId":"8fc6a325-ac96-4e58-9303-68b6f73d2419"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cdb2c1fc7b64d4fad3091e2cac6d6f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"467a861587cb41eabd1456d9e7356d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"423d7c222f7547b6a4940b57b7c754a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291183fd8c5041049ad5ae09751a9ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b1ca4b7b194de3acc7c2c825744453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ce9335acf34fd48d2aefb6ccdf4088"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["BETO model loaded successfully!\n","Starting BETO embedding generation...\n","Found 104 transcript files\n"]},{"output_type":"stream","name":"stderr","text":["Processing files:   3%|▎         | 3/104 [00:00<00:26,  3.77it/s]"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"425ec0c07d5346859637039e14998c72"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Processing files: 100%|██████████| 104/104 [00:14<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Embeddings saved to /content/drive/Shareddrives/NLP/transcriptions/beto_embeddings.csv\n","\n","Embedding generation completed!\n","Processed 104 files\n","Embedding dimension: 768\n","First embedding shape: (768,)\n","First embedding sample (first 10 dims): [ 0.26182157 -0.43910819  0.27464247 -0.16144565  0.76865429  0.21929124\n"," -0.16313431 -0.1653112  -0.24447471 -0.02274783]\n"]}]},{"cell_type":"markdown","source":["Fine-tuning"],"metadata":{"id":"pDK6r-Ca1RJ9"}},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForMaskedLM, get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import random\n","\n","class TranscriptDataset(Dataset):\n","    def __init__(self, texts, tokenizer, max_length=512):\n","        self.texts = texts\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","\n","        # Tokenize the text\n","        encoding = self.tokenizer(\n","            text,\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten()\n","        }\n","\n","def prepare_fine_tuning_data(text_dir, train_ratio=0.8):\n","    \"\"\"Prepare data for fine-tuning from transcript files\"\"\"\n","    text_files = [f for f in os.listdir(text_dir) if f.endswith('.txt')]\n","    texts = []\n","\n","    for filename in text_files:\n","        file_path = os.path.join(text_dir, filename)\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                transcript = f.read().strip()\n","            if transcript:\n","                texts.append(transcript)\n","        except Exception as e:\n","            print(f\"Error reading {filename}: {e}\")\n","\n","    # Shuffle and split\n","    random.shuffle(texts)\n","    split_idx = int(len(texts) * train_ratio)\n","    train_texts = texts[:split_idx]\n","    val_texts = texts[split_idx:]\n","\n","    return train_texts, val_texts\n","\n","def fine_tune_mlm(model, tokenizer, train_texts, val_texts, output_dir,\n","                  batch_size=8, epochs=3, learning_rate=2e-5):\n","    \"\"\"\n","    Fine-tune BETO using Masked Language Modeling\n","    \"\"\"\n","    # Create datasets\n","    train_dataset = TranscriptDataset(train_texts, tokenizer)\n","    val_dataset = TranscriptDataset(val_texts, tokenizer)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    # Setup optimizer and scheduler\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    total_steps = len(train_loader) * epochs\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=total_steps\n","    )\n","\n","    # Training loop\n","    model.train()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch + 1}/{epochs}\")\n","        total_loss = 0\n","\n","        for batch in tqdm(train_loader, desc=\"Training\"):\n","            # Move batch to device\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            # Prepare inputs for MLM - randomly mask tokens\n","            inputs = input_ids.clone()\n","            labels = input_ids.clone()\n","\n","            # Create random mask (15% of tokens)\n","            probability_matrix = torch.full(labels.shape, 0.15)\n","            masked_indices = torch.bernoulli(probability_matrix).bool()\n","            labels[~masked_indices] = -100  # Only compute loss on masked tokens\n","\n","            # 80% of the time, replace masked tokens with [MASK]\n","            indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n","            inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n","\n","            # 10% of the time, replace masked tokens with random word\n","            indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n","            random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long).to(device)\n","            inputs[indices_random] = random_words[indices_random]\n","\n","            # Forward pass\n","            outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","\n","            # Backward pass\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Average training loss: {avg_loss:.4f}\")\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for batch in tqdm(val_loader, desc=\"Validation\"):\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","\n","                # Prepare inputs for MLM\n","                inputs = input_ids.clone()\n","                labels = input_ids.clone()\n","                probability_matrix = torch.full(labels.shape, 0.15)\n","                masked_indices = torch.bernoulli(probability_matrix).bool()\n","                labels[~masked_indices] = -100\n","\n","                outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n","                val_loss += outputs.loss.item()\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        print(f\"Average validation loss: {avg_val_loss:.4f}\")\n","        model.train()\n","\n","    # Save the fine-tuned model\n","    model.save_pretrained(output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","    print(f\"Fine-tuned model saved to {output_dir}\")\n","\n","def get_fine_tuned_embeddings(text, model, tokenizer, method=\"mean\"):\n","    \"\"\"\n","    Get embeddings using fine-tuned model\n","    \"\"\"\n","    # Use the base model for embeddings (not the MLM head)\n","    base_model = model.bert if hasattr(model, 'bert') else model.base_model\n","\n","    inputs = tokenizer(\n","        text,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=True,\n","        max_length=512,\n","        return_attention_mask=True\n","    )\n","\n","    device = next(model.parameters()).device\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = base_model(**inputs)\n","\n","    if method == \"cls\":\n","        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","    elif method == \"mean\":\n","        attention_mask = inputs['attention_mask']\n","        token_embeddings = outputs.last_hidden_state\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","        embedding = (sum_embeddings / sum_mask).cpu().numpy()\n","    elif method == \"pooler\":\n","        embedding = outputs.pooler_output.cpu().numpy()\n","    else:\n","        raise ValueError(\"Method must be 'mean', 'cls', or 'pooler'\")\n","\n","    return embedding.squeeze()\n","\n","def main():\n","    # Set device\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","\n","    BASE_DIR = \"/content/drive/Shareddrives/NLP/transcriptions\"\n","    TEXT_DIR = os.path.join(BASE_DIR, \"all_transcriptions\")\n","    FINE_TUNED_DIR = os.path.join(BASE_DIR, \"fine_tuned_beto\")\n","\n","    # Load model for masked language modeling\n","    model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForMaskedLM.from_pretrained(model_name)\n","\n","    print(\"Original BETO model loaded successfully!\")\n","\n","    # Prepare data for fine-tuning\n","    print(\"Preparing data for fine-tuning...\")\n","    train_texts, val_texts = prepare_fine_tuning_data(TEXT_DIR)\n","\n","    print(f\"Training samples: {len(train_texts)}\")\n","    print(f\"Validation samples: {len(val_texts)}\")\n","\n","    # Fine-tune the model\n","    print(\"Starting fine-tuning...\")\n","    fine_tune_mlm(\n","        model=model,\n","        tokenizer=tokenizer,\n","        train_texts=train_texts,\n","        val_texts=val_texts,\n","        output_dir=FINE_TUNED_DIR,\n","        batch_size=8,\n","        epochs=3,\n","        learning_rate=2e-5\n","    )\n","\n","    # Load fine-tuned model for embedding generation\n","    print(\"Loading fine-tuned model...\")\n","    fine_tuned_model = AutoModelForMaskedLM.from_pretrained(FINE_TUNED_DIR)\n","    fine_tuned_model.to(device)\n","    fine_tuned_model.eval()\n","\n","    # Generate embeddings with fine-tuned model\n","    def process_with_fine_tuned(text_dir, output_file=\"fine_tuned_embeddings.csv\"):\n","        text_files = [f for f in os.listdir(text_dir) if f.endswith('.txt')]\n","        embeddings_data = []\n","\n","        for filename in tqdm(text_files, desc=\"Generating fine-tuned embeddings\"):\n","            file_path = os.path.join(text_dir, filename)\n","\n","            try:\n","                with open(file_path, 'r', encoding='utf-8') as f:\n","                    transcript = f.read().strip()\n","\n","                if not transcript:\n","                    continue\n","\n","                # Get embeddings using fine-tuned model\n","                mean_embedding = get_fine_tuned_embeddings(transcript, fine_tuned_model, tokenizer, \"mean\")\n","                cls_embedding = get_fine_tuned_embeddings(transcript, fine_tuned_model, tokenizer, \"cls\")\n","\n","                embeddings_data.append({\n","                    'filename': filename,\n","                    'text_length': len(transcript),\n","                    'mean_embedding': mean_embedding.tolist(),\n","                    'cls_embedding': cls_embedding.tolist(),\n","                    'embedding_dim': len(mean_embedding)\n","                })\n","\n","            except Exception as e:\n","                print(f\"Error processing {filename}: {str(e)}\")\n","                continue\n","\n","        df = pd.DataFrame(embeddings_data)\n","        output_path = os.path.join(BASE_DIR, output_file)\n","        df.to_csv(output_path, index=False)\n","        print(f\"Fine-tuned embeddings saved to {output_path}\")\n","        return df\n","\n","    # Generate embeddings\n","    print(\"Generating embeddings with fine-tuned model...\")\n","    fine_tuned_embeddings = process_with_fine_tuned(TEXT_DIR)\n","\n","    print(\"Fine-tuning and embedding generation completed!\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tC1wGtcR5Tgc","executionInfo":{"status":"ok","timestamp":1761685420347,"user_tz":-60,"elapsed":103716,"user":{"displayName":"Leire Larrauri Olarte","userId":"15613160182125551834"}},"outputId":"27c83b15-a86d-4584-e9da-1a0306e8e786"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Original BETO model loaded successfully!\n","Preparing data for fine-tuning...\n","Training samples: 83\n","Validation samples: 21\n","Starting fine-tuning...\n","Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 4.2870\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average validation loss: 1.5284\n","Epoch 2/3\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 11/11 [00:11<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 3.8599\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average validation loss: 1.5122\n","Epoch 3/3\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 11/11 [00:11<00:00,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 3.7113\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average validation loss: 1.3707\n","Fine-tuned model saved to /content/drive/Shareddrives/NLP/transcriptions/fine_tuned_beto\n","Loading fine-tuned model...\n","Generating embeddings with fine-tuned model...\n"]},{"output_type":"stream","name":"stderr","text":["Generating fine-tuned embeddings: 100%|██████████| 104/104 [00:21<00:00,  4.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Fine-tuned embeddings saved to /content/drive/Shareddrives/NLP/transcriptions/fine_tuned_embeddings.csv\n","Fine-tuning and embedding generation completed!\n"]}]},{"cell_type":"markdown","source":["Pre-trained vs fine-tuned"],"metadata":{"id":"VKacj51526zh"}},{"cell_type":"code","source":["def compare_embeddings(original_csv, fine_tuned_csv):\n","    \"\"\"Compare original and fine-tuned embeddings\"\"\"\n","    orig_df = pd.read_csv(original_csv)\n","    fine_df = pd.read_csv(fine_tuned_csv)\n","\n","    # Convert embeddings to arrays\n","    orig_embeddings = [np.array(eval(x)) for x in orig_df['mean_embedding']]\n","    fine_embeddings = [np.array(eval(x)) for x in fine_df['mean_embedding']]\n","\n","    # Calculate similarities\n","    from sklearn.metrics.pairwise import cosine_similarity\n","\n","    similarities = []\n","    for orig, fine in zip(orig_embeddings, fine_embeddings):\n","        sim = cosine_similarity([orig], [fine])[0][0]\n","        similarities.append(sim)\n","\n","    print(f\"Average cosine similarity between original and fine-tuned: {np.mean(similarities):.4f}\")\n","    print(f\"Similarity std: {np.std(similarities):.4f}\")\n","\n","    return similarities\n","\n","#Usage\n","similarities = compare_embeddings(\n","     \"/content/drive/Shareddrives/NLP/transcriptions/beto_embeddings.csv\",\n","     \"/content/drive/Shareddrives/NLP/transcriptions/fine_tuned_embeddings.csv\"\n"," )"],"metadata":{"id":"mddVjauw25z4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761685447139,"user_tz":-60,"elapsed":524,"user":{"displayName":"Leire Larrauri Olarte","userId":"15613160182125551834"}},"outputId":"3069226a-8abf-49a5-8505-f7c8c29f8a91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average cosine similarity between original and fine-tuned: 0.9126\n","Similarity std: 0.0099\n"]}]}]}